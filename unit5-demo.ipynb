{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ACT-R tutorial unit 5 models in Python"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are links to open the ACT-R Environment GUI and an Experiment window viewer if needed\n",
    "\n",
    "[Open ACT-R Environment GUI](./env-link.html)\n",
    "\n",
    "[View ACT-R Experiment Window](./exp-link.html)\n"]
  },

 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fan Effect models and task"]
 },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fan Effect model and task with perceptual and motor actions"]
 },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first cell below to connect to ACT-R and load the model which uses perceptual and motor actions.\n",
    "\n",
    "Run the second cell to have the model perform one trial (see tutorial unit for details of the parameters), and run the third cell to have the model perform all trials and report the results."
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan.sentence('lawyer','store',True,'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan.experiment()"
   ]
  },  
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fan Effect model and task which does not use perceptual and motor actions"]
 },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first cell below to connect to ACT-R and load the model which does not use perceptual and motor actions.\n",
    "\n",
    "Run the second cell to have the model perform one trial (see tutorial unit for details of the parameters), and run the third cell to have the model perform all trials and report the results."
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import fan_no_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan_no_pm.sentence('lawyer','store',True,'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan_no_pm.experiment()"
   ]
  }, 
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siegler and Shrager addition task"]
 },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first cell below to connect to ACT-R and load the model for the task.\n",
    "\n",
    "Run the second cell to have the model perform one trial for the numbers provided and return the result, and run the third cell to have the model perform all trials the indicated number of times and report the results."
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import siegler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siegler.trial(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siegler.experiment(100)"
   ]
  }, 
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-hit Blackjack assignment"]
 },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model file for the experiment is actr7.x/tutorial/unit5/1hit-blackjack-model.lisp.\n",
    "\n",
    "You can open that file to work on the model using the File:Open menu in the Jupyter interface.\n",
    "\n",
    "Run the first cell below to connect to ACT-R and load the task and model.\n",
    "\n",
    "Run the second cell to have the model play the indicated number of hands (without being reset), and the fourth cell to show the model's learning over the specified number of 100 hand games.\n",
    "\n",
    "If you change the model then you will need to run the fourth cell to reload the model, or you can press the Reload button in the ACT-R Environment GUI to have the updated model loaded.\n"
  },
  
{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import onehit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehit.hands(4)"
   ]
  },
   {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehit.learning(50)"
   ]
  }, 
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actr.reload()"
   ]
  }

 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
